{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import sys\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from scipy import spatial\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use a function to load the movie names corresponding to the movie IDs\n",
    "def loadMovieNames():\n",
    "    movieNames = {}\n",
    "    with open('ml-100k\\u.item') as file:\n",
    "        for line in file:\n",
    "            fields = line.split('|')\n",
    "            movieNames[int(fields[0])] = fields[1].decode('ascii','ignore')\n",
    "            \n",
    "    return movieNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This time we will use a slightly different similarity function. Specifically our function will still be the cosine similarity\n",
    "# metric but will be weighted somehow by the number of ratings available. More the number of ratings, higher the overall \n",
    "# similarity score\n",
    "\n",
    "def filterDuplicates((userid, pairs)):\n",
    "    movie1 = pairs[0][0]\n",
    "    movie2 = pairs[1][0]\n",
    "    return movie1 < movie2\n",
    "\n",
    "# We will pass the number of ratings through a sigmoid function which essentially squashes input between 0 to 1. Higher the \n",
    "# number of ratings, closer is the output of the sigmoid function to 1. Movies with very low number of ratings will have the \n",
    "# sigmoid output close to 0.5. We also choose a rise factor (< 1) that governs how fast the sigmoid saturates to 1.\n",
    "\n",
    "def sigmoid(x,a):\n",
    "    return float(1/(1+ np.exp(-a*x)))\n",
    "\n",
    "\n",
    "# our net similarity is a weighted sum of the cosine similarity and the output of the sigmoid function. The weight is called \n",
    "# alpha\n",
    "def similarityFunc(list_of_ratings):\n",
    "    arr = np.array(list_of_ratings)\n",
    "    # the method gives the distance. 1 - the value is the similarity\n",
    "    sim = 1-spatial.distance.cosine(arr[:,0], arr[:,1])\n",
    "    num_of_pairs = len(list_of_ratings)\n",
    "    weight = sigmoid(num_of_pairs, 0.005) # rise factor of 0.005, essentially means a much slower rise to 1 than standard sigmoid\n",
    "    alpha = 0.5 \n",
    "    weighted_sim = alpha*weight + (1-alpha)*sim\n",
    "    \n",
    "    return (float(weighted_sim), num_of_pairs)\n",
    "    \n",
    "    \n",
    "def makeItemPairs((userid, pairs)):\n",
    "    (movie1, rating1) = pairs[0]\n",
    "    (movie2, rating2) = pairs[1]\n",
    "    \n",
    "    return ((movie1,movie2),(rating1,rating2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((197, 1097), (0.7423110081201001, 7)), ((42, 364), (0.7159167404158419, 18)), ((773, 1409), (0.7506249986979199, 1)), ((273, 617), (0.7370222333904755, 7)), ((372, 974), (0.7506249986979199, 1)), ((789, 865), (0.7467487273331919, 3)), ((496, 1314), (0.7407083328480895, 4)), ((246, 1008), (0.7337086520601352, 18)), ((856, 1006), (0.7405811481955664, 10)), ((747, 795), (0.6623528535395095, 6))]\n"
     ]
    }
   ],
   "source": [
    "# the dataset has 100,000 records. So we will be using all the cores available in the computer\n",
    "# by setting the setMaster argument to 'local[*]'\n",
    "\n",
    "conf = SparkConf().setMaster('local[*]').setAppName('MovieSimi_ver2')\n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "# load the movie names dataset into a large dictionary called names\n",
    "names = loadMovieNames()\n",
    "\n",
    "data = sc.textFile('.\\ml-100k\\u.data')\n",
    "\n",
    "# map ratings in the form of userid as key and (movieid, rating) as value\n",
    "user_ratings = data.map(lambda x: x.split('\\t')).map(lambda parts: (int(parts[0]), (int(parts[1]), float(parts[2]))))\n",
    "\n",
    "# compute a list of movie pairs with rating pairs from all users who have rated that pair of movies\n",
    "# this will have each record in the form userid as key and  ((movieid1, rating1), (movieid2, rating2)) as the value\n",
    "movie_ratings = user_ratings.join(user_ratings)\n",
    "\n",
    "# removing duplicates...since a join could result in both movies being same and all combinations of the same movie pair in \n",
    "# different orders. We will only keep the movies where the first id is less than the second id. \n",
    "movie_ratings_clean = movie_ratings.filter(filterDuplicates)\n",
    "\n",
    "# the records are still in the form userid as key and  ((movieid1, rating1), (movieid2, rating2)) as the value\n",
    "# convert this rdd to the form (movieid1, movieid2) as the key and (rating1,rating2) as the value\n",
    "\n",
    "movie_pairs = movie_ratings_clean.map(makeItemPairs)\n",
    "\n",
    "# Now we will group by movie pairs to find all available pairs of ratings for each unique movie pair\n",
    "movie_pairs_group = movie_pairs.groupByKey().map(lambda (x,y) : (x, list(y)))\n",
    "\n",
    "#now for each movie pair as the key the value is a list of rating pairs collected from all users. We will consider each rating\n",
    "# pair as elements from two vectors and essentially compute the similarity of the two vectors, each vector being the collection\n",
    "# of ratings\n",
    "\n",
    "movie_pair_simi = movie_pairs_group.mapValues(similarityFunc).persist() #we cache this rdd as this will be used later\n",
    "\n",
    "# each record is now of the form (movieid1, movieid2) as key and (similarity, number of rating pairs) as the value\n",
    "print movie_pair_simi.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 similar movies for the movie:  Star Wars (1977)\n",
      "\n",
      "Return of the Jedi (1983) with score: 0.95 from 480 ratings\n",
      "Raiders of the Lost Ark (1981) with score: 0.93 from 380 ratings\n",
      "Empire Strikes Back, The (1980) with score: 0.92 from 345 ratings\n",
      "Toy Story (1995) with score: 0.92 from 381 ratings\n",
      "Fargo (1996) with score: 0.92 from 394 ratings\n",
      "Godfather, The (1972) with score: 0.91 from 357 ratings\n",
      "Independence Day (ID4) (1996) with score: 0.9 from 362 ratings\n",
      "Silence of the Lambs, The (1991) with score: 0.9 from 335 ratings\n",
      "Contact (1997) with score: 0.9 from 334 ratings\n",
      "Star Trek: First Contact (1996) with score: 0.9 from 316 ratings\n",
      "Indiana Jones and the Last Crusade (1989) with score: 0.9 from 304 ratings\n",
      "Twelve Monkeys (1995) with score: 0.9 from 324 ratings\n",
      "Back to the Future (1985) with score: 0.9 from 309 ratings\n",
      "Fugitive, The (1993) with score: 0.89 from 297 ratings\n",
      "Pulp Fiction (1994) with score: 0.89 from 330 ratings\n",
      "Rock, The (1996) with score: 0.89 from 312 ratings\n",
      "Princess Bride, The (1987) with score: 0.89 from 284 ratings\n",
      "Jerry Maguire (1996) with score: 0.88 from 296 ratings\n",
      "Terminator, The (1984) with score: 0.88 from 278 ratings\n",
      "Monty Python and the Holy Grail (1974) with score: 0.88 from 278 ratings\n"
     ]
    }
   ],
   "source": [
    "# now we will get the similar movies for the user provided movie id\n",
    "# Let's choose movie ID 50 which is a Star Wars movie\n",
    "\n",
    "user_choice = 50\n",
    "num_of_reco = 20 # number of similar movie suggestions to be sent to the output \n",
    "\n",
    "num_of_ratings = 50 # to select the similar movies which have atleast this number of ratings\n",
    "    \n",
    "# filter the movies which satisfy the given criteria\n",
    "\n",
    "results = movie_pair_simi.filter( lambda (pair, (sim,num)) : (user_choice in  pair) and (num >= num_of_ratings))\n",
    "results_final  = results.map(lambda (x,y) : (y,x)).sortByKey(ascending = False).take(num_of_reco)\n",
    "\n",
    "\n",
    "print 'Top {} similar movies for the movie:  {}\\n'.format(num_of_reco, names[user_choice])\n",
    "for val in results_final:\n",
    "    ((sim,num),pair) = val\n",
    "    similarMovies = pair[0]\n",
    "    if similarMovies==user_choice:\n",
    "        similarMovies=  pair[1]\n",
    "        \n",
    "    print names[similarMovies] + ' with score: {:.2} from {} ratings'.format(sim, num)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The modified weighted similarity metric does slightly better. For example we see a 'Star Trek' and 'Terminator' movie included\n",
    "# in the suggestions which are clearly science fiction and better recommendations than movies like \"Glory\" and \"Usual Suspects\" \n",
    "# both of which are now absent. Still we can do better. In the next version we will incorporate genre information alongwith \n",
    "# the weighted similarity measure to see how the results differ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
