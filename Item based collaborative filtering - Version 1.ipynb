{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import sys\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from scipy import spatial\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use a function to load the movie names corresponding to the movie IDs\n",
    "def loadMovieNames():\n",
    "    movieNames = {}\n",
    "    with open('ml-100k\\u.item') as file:\n",
    "        for line in file:\n",
    "            fields = line.split('|')\n",
    "            movieNames[int(fields[0])] = fields[1].decode('ascii','ignore')\n",
    "            \n",
    "    return movieNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some other functions that we will apply to the various RDDs we create along the way. The function names are self explanatory\n",
    "def filterDuplicates((userid, pairs)):\n",
    "    movie1 = pairs[0][0]\n",
    "    movie2 = pairs[1][0]\n",
    "    return movie1 < movie2\n",
    "            \n",
    "    \n",
    "def similarityFunc(list_of_ratings):\n",
    "    arr = np.array(list_of_ratings)\n",
    "    # the method gives the distance. 1 - the value is the similarity\n",
    "    sim = 1-spatial.distance.cosine(arr[:,0], arr[:,1])\n",
    "    num_of_pairs = len(list_of_ratings)\n",
    "    \n",
    "    return (float(sim), num_of_pairs)    \n",
    " \n",
    "def makeItemPairs((userid, pairs)):\n",
    "    (movie1, rating1) = pairs[0]\n",
    "    (movie2, rating2) = pairs[1]\n",
    "    \n",
    "    return ((movie1,movie2),(rating1,rating2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((197, 1097), (0.9758729093599599, 7)), ((42, 364), (0.9093486560398836, 18)), ((773, 1409), (1.0, 1)), ((273, 617), (0.9652953599007105, 7)), ((372, 974), (1.0, 1)), ((789, 865), (0.9897475249773018, 3)), ((496, 1314), (0.976416832356179, 4)), ((246, 1008), (0.9449324793284705, 18)), ((856, 1006), (0.9686648999069224, 10)), ((747, 795), (0.8172062695283986, 6))]\n"
     ]
    }
   ],
   "source": [
    "# the dataset has 100,000 records. So we will be using all the cores available in the computer\n",
    "# by setting the setMaster argument to 'local[*]'\n",
    "conf = SparkConf().setMaster('local[*]').setAppName('MovieSimi_ver1')\n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "# load the movie names dataset into a large dictionary called names\n",
    "names = loadMovieNames()\n",
    "\n",
    "data = sc.textFile('.\\ml-100k\\u.data')\n",
    "\n",
    "# map ratings in the form of userid as key and (movieid, rating) as value\n",
    "\n",
    "user_ratings = data.map(lambda x: x.split('\\t')).map(lambda parts: (int(parts[0]), (int(parts[1]), float(parts[2]))))\n",
    "\n",
    "# compute a list of movie pairs with rating pairs from all users who have rated that pair of movies\n",
    "# this will have each record in the form userid as key and  ((movieid1, rating1), (movieid2, rating2)) as the value\n",
    "\n",
    "movie_ratings = user_ratings.join(user_ratings)\n",
    "\n",
    "# removing duplicates...since a join could result in both movies being same and all combinations of the same movie pair in\n",
    "# different order. We will only keep the movies where the first id is less than the second id. \n",
    "\n",
    "movie_ratings_clean = movie_ratings.filter(filterDuplicates)\n",
    "\n",
    "# the records are still in the form userid as key and  ((movieid1, rating1), (movieid2, rating2)) as the value\n",
    "# convert this rdd to the form (movieid1, movieid2) as the key and (rating1,rating2) as the value\n",
    "\n",
    "movie_pairs = movie_ratings_clean.map(makeItemPairs)\n",
    "\n",
    "# Now we will group by movie pairs to find all available pairs of ratings for each unique movie pair\n",
    "movie_pairs_group = movie_pairs.groupByKey().map(lambda (x,y) : (x, list(y)))\n",
    "\n",
    "# now for each movie pair as the key, the corresponding value is a list of rating pairs collected from all users. We will \n",
    "# consider each rating pair as elements from two vectors and essentially compute the similarity of the two vectors\n",
    "# each vector being the collection of ratings\n",
    "\n",
    "movie_pair_simi = movie_pairs_group.mapValues(similarityFunc).persist() #we cache this rdd as this will be used later\n",
    "\n",
    "# each record is now of the form (movieid1, movieid2) as key and (similarity, number of rating pairs) as the value\n",
    "print movie_pair_simi.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 similar movies for the movie:  Star Wars (1977)\n",
      "\n",
      "Empire Strikes Back, The (1980) with score: 0.99 from 345 ratings\n",
      "Return of the Jedi (1983) with score: 0.99 from 480 ratings\n",
      "Raiders of the Lost Ark (1981) with score: 0.98 from 380 ratings\n",
      "20,000 Leagues Under the Sea (1954) with score: 0.98 from 68 ratings\n",
      "12 Angry Men (1957) with score: 0.98 from 109 ratings\n",
      "Close Shave, A (1995) with score: 0.98 from 92 ratings\n",
      "African Queen, The (1951) with score: 0.98 from 138 ratings\n",
      "Sting, The (1973) with score: 0.98 from 204 ratings\n",
      "Wrong Trousers, The (1993) with score: 0.97 from 103 ratings\n",
      "Wallace & Gromit: The Best of Aardman Animation (1996) with score: 0.97 from 58 ratings\n",
      "Indiana Jones and the Last Crusade (1989) with score: 0.97 from 304 ratings\n",
      "North by Northwest (1959) with score: 0.97 from 156 ratings\n",
      "Philadelphia Story, The (1940) with score: 0.97 from 87 ratings\n",
      "Bridge on the River Kwai, The (1957) with score: 0.97 from 145 ratings\n",
      "Casablanca (1942) with score: 0.97 from 214 ratings\n",
      "L.A. Confidential (1997) with score: 0.97 from 158 ratings\n",
      "Usual Suspects, The (1995) with score: 0.97 from 223 ratings\n",
      "Around the World in 80 Days (1956) with score: 0.97 from 52 ratings\n",
      "Right Stuff, The (1983) with score: 0.97 from 142 ratings\n",
      "Glory (1989) with score: 0.97 from 155 ratings\n"
     ]
    }
   ],
   "source": [
    "# now we will get the similar movies for the user provided movie id\n",
    "# Let's choose movie ID 50 which is a Star Wars movie\n",
    "\n",
    "user_choice = 50\n",
    "num_of_reco = 20 # number of similar movie suggestions to be sent to the output \n",
    "    \n",
    "sim_thresh = 0.95 # similar to the chosen movie by atleast this amount\n",
    "num_of_ratings = 50 # to select the similar movies which have atleast this number of ratings\n",
    "    \n",
    "# filter the movies which satisfy the given criteria\n",
    "\n",
    "results = movie_pair_simi.filter( lambda (pair, (sim,num)) : (user_choice in  pair) and (sim >= sim_thresh) and\\\n",
    "                                 (num >= num_of_ratings))\n",
    "\n",
    "results_final  = results.map(lambda (x,y) : (y,x)).sortByKey(ascending = False).take(num_of_reco)\n",
    "\n",
    "\n",
    "print 'Top {} similar movies for the movie:  {}\\n'.format(num_of_reco, names[user_choice])\n",
    "for val in results_final:\n",
    "    ((sim,num),pair) = val\n",
    "    similarMovies = pair[0]\n",
    "    if similarMovies==user_choice:\n",
    "        similarMovies=  pair[1]\n",
    "        \n",
    "    print names[similarMovies] + ' with score: {:.2} from {} ratings'.format(sim, num)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We do see some rather irrelevant movies like \"Usual Suspects\" and \"Glory\" which are not science fiction and definitely not\n",
    "# related to space and technology. In the next part we will try to improve the current algorithm by incorporating more \n",
    "# information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
